{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• Clinical Triage Router\n",
    "\n",
    "**A specialized SLM agent (‚â§3B) for patient intake classification**\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Synthetic Data Generation** - Gemini 1.5 Flash (free tier)\n",
    "2. **Fine-Tuning** - Unsloth + LoRA on Qwen2.5-1.5B (4-bit)\n",
    "3. **Agentic Loop** - Self-correction with retry logic\n",
    "4. **Evaluation** - JSON validity & routing accuracy metrics\n",
    "\n",
    "---\n",
    "**Author**: Adarsh P  \n",
    "**Runtime**: Google Colab T4 GPU (Free Tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with 'Python 3.14.2' requires the jupyter and notebook package.\n",
      "\u001b[1;31mInstall 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Install dependencies (Colab T4 GPU)\n",
    "!pip install -q unsloth\n",
    "!pip install -q --no-deps xformers trl peft accelerate bitsandbytes\n",
    "!pip install -q google-generativeai pydantic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/forkadarshp/clinic-triage.git\n",
    "%cd clinic-triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports\n",
    "from src import config\n",
    "from src.schemas import ToolName, parse_triage_output, get_mock_response\n",
    "\n",
    "print(f\"‚úÖ Model: {config.MODEL_NAME}\")\n",
    "print(f\"‚úÖ Tools: {[t.value for t in ToolName]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìã Phase 1: Synthetic Data Generation & Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generate Training Data (Gemini 1.5 Flash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set API keys (Gemini or OpenAI supported)\n",
    "try:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "except: pass\n",
    "\n",
    "print(\"‚úÖ API keys configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import generate_training_data, load_training_data\n",
    "\n",
    "# Generate training examples\n",
    "examples = generate_training_data(num_examples=config.NUM_TRAINING_EXAMPLES)\n",
    "print(f\"\\nüìä Generated {len(examples)} examples\")\n",
    "print(f\"\\nSample:\\n{examples[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Model (4-bit Quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import load_model_and_tokenizer, prepare_model_for_training\n",
    "\n",
    "# Load pre-quantized model\n",
    "model, tokenizer = load_model_and_tokenizer()\n",
    "print(f\"‚úÖ Loaded {config.MODEL_NAME}\")\n",
    "\n",
    "# Add LoRA adapters\n",
    "model = prepare_model_for_training(model)\n",
    "print(f\"‚úÖ LoRA adapters added (r={config.LORA_R})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import prepare_dataset, train\n",
    "\n",
    "# Prepare dataset\n",
    "dataset = prepare_dataset(tokenizer)\n",
    "print(f\"üìä Training set: {len(dataset)} examples\")\n",
    "\n",
    "# Train\n",
    "model = train(model, tokenizer, dataset)\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ Phase 2: The Agentic Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Prepare model for inference\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent import TriageAgent\n",
    "\n",
    "# Initialize agent with trained model\n",
    "agent = TriageAgent(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "test_query = \"\"\"65yo male, crushing chest pain radiating to jaw and left arm.\n",
    "Started 20 minutes ago. Diaphoretic, nauseous. History of hypertension.\n",
    "Location: 789 Pine Street.\"\"\"\n",
    "\n",
    "output, response, metadata = agent.run(test_query)\n",
    "\n",
    "print(\"üìã Query:\", test_query[:80], \"...\")\n",
    "print(\"\\nüîß Tool Called:\", output.tool if output else \"FAILED\")\n",
    "print(\"üì¶ Arguments:\", output.arguments.model_dump() if output else \"N/A\")\n",
    "print(\"\\nüí¨ Response:\", response)\n",
    "print(f\"\\nüîÑ Attempts: {metadata['attempts']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Phase 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluator import load_test_data, evaluate, print_report\n",
    "\n",
    "# Load 10 held-out test cases\n",
    "test_data = load_test_data()\n",
    "print(f\"üìã Loaded {len(test_data)} test cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "results = evaluate(agent, test_data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final report\n",
    "print_report(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Summary\n",
    "\n",
    "| Metric | Result |\n",
    "|--------|--------|\n",
    "| **Model** | Qwen2.5-1.5B (4-bit) |\n",
    "| **Training Examples** | config.NUM_TRAINING_EXAMPLES |\n",
    "| **JSON Validity** | TBD% |\n",
    "| **Routing Accuracy** | TBD% |\n",
    "| **Routing MSE** | TBD |\n",
    "\n",
    "### Key Features\n",
    "- ‚úÖ Runs on Colab Free Tier (T4 GPU)\n",
    "- ‚úÖ 4-bit quantization for memory efficiency\n",
    "- ‚úÖ Self-correction with 3-retry logic\n",
    "- ‚úÖ Pydantic validation for strict schema adherence\n",
    "- ‚úÖ Gemini Flash for zero-cost data generation"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
